{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Reading files\n",
    "## No need to iterate in order to optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['routes/CAR/logfile_CAR_R1_S3.txt', 'routes/CAR/logfile_CAR_R1_S3mini.txt', 'routes/CAR/logfile_CAR_R2_S3.txt', 'routes/CAR/logfile_CAR_R2_S4.txt'], ['routes/UAH/logfile_UAH_R1_S3.txt', 'routes/UAH/logfile_UAH_R1_S4.txt', 'routes/UAH/logfile_UAH_R2_S3.txt', 'routes/UAH/logfile_UAH_R2_S4.txt', 'routes/UAH/logfile_UAH_R4_S3.txt', 'routes/UAH/logfile_UAH_R4_S4.txt'], ['routes/UJITI/logfile_UJITI_R1_NEXUS5.txt', 'routes/UJITI/logfile_UJITI_R2_NEXUS5.txt'], ['routes/UJIUB/logfile_UJIUB_R1n_S3.txt', 'routes/UJIUB/logfile_UJIUB_R1r_S3.txt', 'routes/UJIUB/logfile_UJIUB_R2n_S3.txt', 'routes/UJIUB/logfile_UJIUB_R2r_S3.txt', 'routes/UJIUB/logfile_UJIUB_R3_S3.txt']]\n",
      "There are 17 files\n"
     ]
    }
   ],
   "source": [
    "# get train file names\n",
    "import glob\n",
    "\n",
    "train_folders = ['CAR', 'UAH', 'UJITI', 'UJIUB']\n",
    "\n",
    "files_names = []\n",
    "n_files = 0\n",
    "for building in train_folders:\n",
    "    cur_file_names = glob.glob('routes/' + building + '/log*')\n",
    "    files_names.append(sorted(cur_file_names))\n",
    "    n_files += len(cur_file_names)\n",
    "\n",
    "print(files_names)\n",
    "print('There are %d files' % n_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "routes/CAR/logfile_CAR_R1_S3.txt\n",
      "['ACCE' 'AHRS' 'GNSS' 'GYRO' 'LIGH' 'MAGN' 'POSI' 'PRES' 'SOUN' 'WIFI']\n",
      "routes/CAR/logfile_CAR_R1_S3mini.txt\n",
      "['ACCE' 'AHRS' 'GNSS' 'GYRO' 'MAGN' 'POSI' 'SOUN' 'WIFI']\n",
      "routes/CAR/logfile_CAR_R2_S3.txt\n",
      "['ACCE' 'AHRS' 'GNSS' 'GYRO' 'LIGH' 'MAGN' 'POSI' 'PRES' 'PROX' 'SOUN'\n",
      " 'WIFI']\n",
      "routes/CAR/logfile_CAR_R2_S4.txt\n",
      "['ACCE' 'AHRS' 'GNSS' 'GYRO' 'HUMI' 'LIGH' 'MAGN' 'POSI' 'PRES' 'PROX'\n",
      " 'SOUN' 'TEMP' 'WIFI']\n",
      "routes/UAH/logfile_UAH_R1_S3.txt\n",
      "['ACCE' 'AHRS' 'GNSS' 'GYRO' 'LIGH' 'MAGN' 'POSI' 'PRES' 'SOUN' 'WIFI']\n",
      "routes/UAH/logfile_UAH_R1_S4.txt\n",
      "['ACCE' 'AHRS' 'GNSS' 'GYRO' 'HUMI' 'LIGH' 'MAGN' 'POSI' 'PRES' 'SOUN'\n",
      " 'TEMP' 'WIFI']\n",
      "routes/UAH/logfile_UAH_R2_S3.txt\n",
      "['ACCE' 'AHRS' 'GNSS' 'GYRO' 'LIGH' 'MAGN' 'POSI' 'PRES' 'SOUN' 'WIFI']\n",
      "routes/UAH/logfile_UAH_R2_S4.txt\n",
      "['ACCE' 'AHRS' 'GNSS' 'GYRO' 'HUMI' 'LIGH' 'MAGN' 'POSI' 'PRES' 'SOUN'\n",
      " 'TEMP' 'WIFI']\n",
      "routes/UAH/logfile_UAH_R4_S3.txt\n",
      "['ACCE' 'AHRS' 'GNSS' 'GYRO' 'LIGH' 'MAGN' 'POSI' 'PRES' 'SOUN' 'WIFI']\n",
      "routes/UAH/logfile_UAH_R4_S4.txt\n",
      "['ACCE' 'AHRS' 'GNSS' 'GYRO' 'HUMI' 'LIGH' 'MAGN' 'POSI' 'PRES' 'SOUN'\n",
      " 'TEMP' 'WIFI']\n",
      "routes/UJITI/logfile_UJITI_R1_NEXUS5.txt\n",
      "['ACCE' 'AHRS' 'GNSS' 'GYRO' 'LIGH' 'MAGN' 'POSI' 'PRES' 'PROX' 'SOUN'\n",
      " 'WIFI']\n",
      "routes/UJITI/logfile_UJITI_R2_NEXUS5.txt\n",
      "['ACCE' 'AHRS' 'GYRO' 'LIGH' 'MAGN' 'POSI' 'PRES' 'SOUN' 'WIFI']\n",
      "routes/UJIUB/logfile_UJIUB_R1n_S3.txt\n",
      "['ACCE' 'AHRS' 'GNSS' 'GYRO' 'LIGH' 'MAGN' 'POSI' 'PRES' 'PROX' 'SOUN'\n",
      " 'WIFI']\n",
      "routes/UJIUB/logfile_UJIUB_R1r_S3.txt\n",
      "['ACCE' 'AHRS' 'GNSS' 'GYRO' 'LIGH' 'MAGN' 'POSI' 'PRES' 'SOUN' 'WIFI']\n",
      "routes/UJIUB/logfile_UJIUB_R2n_S3.txt\n",
      "['ACCE' 'AHRS' 'GNSS' 'GYRO' 'LIGH' 'MAGN' 'POSI' 'PRES' 'PROX' 'SOUN'\n",
      " 'WIFI']\n",
      "routes/UJIUB/logfile_UJIUB_R2r_S3.txt\n",
      "['ACCE' 'AHRS' 'GNSS' 'GYRO' 'LIGH' 'MAGN' 'POSI' 'PRES' 'SOUN' 'WIFI']\n",
      "routes/UJIUB/logfile_UJIUB_R3_S3.txt\n",
      "['ACCE' 'AHRS' 'GNSS' 'GYRO' 'LIGH' 'MAGN' 'POSI' 'PRES' 'PROX' 'SOUN'\n",
      " 'WIFI']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/IPython/core/interactiveshell.py:2723: DtypeWarning: Columns (3,4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# import files into dataframes\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "track= []\n",
    "for building in files_names:\n",
    "    track.append([])\n",
    "    for track_name in building:\n",
    "        print(track_name)\n",
    "        track[-1].append(pd.read_csv(track_name, sep=';', engine='c', names=range(11)))\n",
    "        print(np.unique(track[-1][-1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "routes/UAH/logfile_UAH_R2_S3.txt\n",
      "64\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  3.  3.  3.  3.\n",
      "  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.\n",
      "  3.  3.  2.  1.  0.  0.  0.  0.  0.  0.]\n",
      "         Time  index          Lat       Lon  FloorID  BuildingID  \\\n",
      "4142    8.618    1.0  40.51278407  -3.34849      0.0        20.0   \n",
      "16724  34.656    2.0  40.51296307  -3.34844      0.0        20.0   \n",
      "24993  51.802    3.0  40.51296539  -3.34859      0.0        20.0   \n",
      "32452  67.263    4.0  40.51302711  -3.34866      0.0        20.0   \n",
      "39755  82.372    5.0  40.51307726  -3.34879      0.0        20.0   \n",
      "\n",
      "       ind_begin_time  ind_end_time  \n",
      "4142           0.0000       21.6370  \n",
      "16724         21.6370       43.2290  \n",
      "24993         43.2290       59.5325  \n",
      "32452         59.5325       74.8175  \n",
      "39755         74.8175       92.8480  \n"
     ]
    }
   ],
   "source": [
    "# Find time limits per POSI id\n",
    "def posi_time_limits(pos_array):\n",
    "    # create start and end index time array\n",
    "    pos_array['ind_begin_time'] = np.zeros((pos_array.shape[0]))\n",
    "    pos_array['ind_end_time'] = np.zeros((pos_array.shape[0]))\n",
    "    pos_array['ind_end_time'].iat[-1] = 99999\n",
    "\n",
    "    for i in range(1, pos_array.shape[0]):\n",
    "        cur_split = (float(pos_array['Time'].iloc[i]) + float(pos_array['Time'].iloc[i-1])) / 2\n",
    "        pos_array['ind_begin_time'].iat[i] = cur_split       \n",
    "        pos_array['ind_end_time'].iat[i-1] = cur_split       \n",
    "    return pos_array\n",
    "\n",
    "# create true ground dataframes\n",
    "pos = []\n",
    "for i in range(len(track)):\n",
    "    pos.append([])\n",
    "    for j in range(len(track[i])):\n",
    "        pos[i].append(track[i][j][[1, 2, 3, 4, 5, 6, 7]].iloc[track[i][j][0].values == 'POSI'])\n",
    "        pos[i][j] = pos[i][j].dropna(axis=1)\n",
    "        pos[i][j].columns = ['Time', 'index', 'Lat', 'Lon', 'FloorID', 'BuildingID']\n",
    "        pos[i][j] = posi_time_limits(pos[i][j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0      1       2         3        4         5        6        7  \\\n",
      "0  GYRO  0.018  89.931   0.58521  0.41692  -0.74526  3.00000      NaN   \n",
      "1  AHRS  0.019  89.931   36.8048   5.5949 -32.75710  0.31558 -0.04448   \n",
      "2  LIGH  0.020  89.940    2124.0        0       NaN      NaN      NaN   \n",
      "3  ACCE  0.020  89.941  -1.38864  6.10043   7.44118  3.00000      NaN   \n",
      "4  GYRO  0.031  89.951  -0.48686  0.38546   0.01344  3.00000      NaN   \n",
      "\n",
      "         8     9  10  POSI_floor  POSI_building  \n",
      "0      NaN   NaN NaN         0.0           30.0  \n",
      "1 -0.25246 -43.0 NaN         0.0           30.0  \n",
      "2      NaN   NaN NaN         0.0           30.0  \n",
      "3      NaN   NaN NaN         0.0           30.0  \n",
      "4      NaN   NaN NaN         0.0           30.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/pandas/core/indexing.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "# associate signals with POSI ids. Spliting at middle of the time between POSI measurements using posi_time_limits\n",
    "for i in range(len(track)):\n",
    "    for j in range(len(track[i])):\n",
    "        track[i][j]['POSI_floor'] = np.zeros((track[i][j].shape[0])) * np.nan\n",
    "        track[i][j]['POSI_building'] = np.zeros((track[i][j].shape[0])) * np.nan\n",
    "        for k in range(pos[i][j].shape[0]):\n",
    "            ind_begin_time = pos[i][j]['ind_begin_time'].iloc[k]\n",
    "            ind_end_time = pos[i][j]['ind_end_time'].iloc[k]\n",
    "    \n",
    "            ind = pos[i][j]['index'].iloc[k]\n",
    "            ind_floor = pos[i][j]['FloorID'].iloc[k]\n",
    "            ind_building = pos[i][j]['BuildingID'].iloc[k]\n",
    "            \n",
    "            index_limits = np.logical_and(track[i][j][1].values >= ind_begin_time, \n",
    "                                          track[i][j][1].values < ind_end_time)\n",
    "            \n",
    "            track[i][j]['POSI_floor'].iloc[index_limits] = ind_floor\n",
    "            track[i][j]['POSI_building'].iloc[index_limits] = ind_building\n",
    "\n",
    "print(track[i][j].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pad ground truth in order to use interpolation later\n",
    "for i in range(len(track)):\n",
    "    for j in range(len(track[i])):\n",
    "        pos_pad_start = pos[i][j].iloc[0]\n",
    "        pos_pad_start.at['Time'] = 0\n",
    "        pos_pad_end = pos[i][j].iloc[-1]\n",
    "        pos_pad_end.at['Time'] = track[i][j][1].values[-1]\n",
    "        pos_array = np.vstack((pos_pad_start.values.reshape((1, pos[i][j].shape[1])), \n",
    "                                pos[i][j].values, \n",
    "                                pos_pad_end.values.reshape((1, pos[i][j].shape[1]))))\n",
    "        pos[i][j] = pd.DataFrame(pos_array, columns=pos[i][j].columns.values)\n",
    "\n",
    "i = 1\n",
    "j = 2\n",
    "print(files_names[i][j])\n",
    "print(pos[i][j].shape[0])\n",
    "print(pos[i][j]['FloorID'].values)\n",
    "print(pos[i][j].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0      1         2         3          4          5        6       7  \\\n",
      "0  ACCE  0.094  4292.788  -1.38864    4.62560    8.40844  3.00000     NaN   \n",
      "1  MAGN  0.095  4292.788  -5.64000  -39.72000  -19.56000  3.00000     NaN   \n",
      "2  GYRO  0.097  4292.792  -0.16432   -0.20861   -0.19609  3.00000     NaN   \n",
      "3  AHRS  0.098  4292.792   28.5264     9.6349 -161.85360  0.11909 -0.2296   \n",
      "4  LIGH  0.098  4292.792   14561.0          3        NaN      NaN     NaN   \n",
      "\n",
      "        8    9  10  POSI_floor  POSI_building  interp_lat  interp_lon  \n",
      "0     NaN  NaN NaN         0.0           10.0   40.313471    -3.48315  \n",
      "1     NaN  NaN NaN         0.0           10.0   40.313471    -3.48315  \n",
      "2     NaN  NaN NaN         0.0           10.0   40.313471    -3.48315  \n",
      "3 -0.9504  3.0 NaN         0.0           10.0   40.313471    -3.48315  \n",
      "4     NaN  NaN NaN         0.0           10.0   40.313471    -3.48315  \n"
     ]
    }
   ],
   "source": [
    "# Interpolate sensors' time\n",
    "import scipy.interpolate as interpolate\n",
    "\n",
    "for i in range(len(track)):\n",
    "    for j in range(len(track[i])):\n",
    "        interp_ground_truth_lat = interpolate.interp1d(pos[i][j]['Time'].astype(float), pos[i][j]['Lat'])\n",
    "        track[i][j]['interp_lat'] = interp_ground_truth_lat(track[i][j][1])\n",
    "        interp_ground_truth_lon = interpolate.interp1d(pos[i][j]['Time'].astype(float), pos[i][j]['Lon'])\n",
    "        track[i][j]['interp_lon'] = interp_ground_truth_lon(track[i][j][1])\n",
    "print(track[0][0].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     AppTime                MAC  rssi  POSI_floor  POSI_building  interp_lat  \\\n",
      "637    2.293  00:0b:86:27:36:c2 -82.0         0.0           10.0   40.313471   \n",
      "638    2.293  00:0b:86:27:32:e0 -66.0         0.0           10.0   40.313471   \n",
      "639    2.293  00:0b:86:27:32:e2 -66.0         0.0           10.0   40.313471   \n",
      "640    2.293  00:0b:86:27:32:e1 -68.0         0.0           10.0   40.313471   \n",
      "641    2.293  00:0b:86:27:36:c0 -82.0         0.0           10.0   40.313471   \n",
      "\n",
      "     interp_lon  \n",
      "637    -3.48315  \n",
      "638    -3.48315  \n",
      "639    -3.48315  \n",
      "640    -3.48315  \n",
      "641    -3.48315  \n"
     ]
    }
   ],
   "source": [
    "# Create wifi data frames\n",
    "wifi = []\n",
    "for i in range(len(track)):\n",
    "    wifi.append([])\n",
    "    for j in range(len(track[i])):\n",
    "        wifi[-1].append(track[i][j][[1, 4, 5, 'POSI_floor', 'POSI_building', 'interp_lat',  \n",
    "                                    'interp_lon']].iloc[track[i][j][0].values == 'WIFI'])\n",
    "        wifi[-1][-1].columns = ['AppTime', 'MAC', 'rssi', 'POSI_floor', 'POSI_building', 'interp_lat', 'interp_lon']\n",
    "print(wifi[0][0].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot debug info\n",
    "DEBUG = True\n",
    "# false if using real test data\n",
    "EVAL = True\n",
    "\n",
    "# split to different tracks in order to not overfit while testing\n",
    "ROUTES = [[0, 0, 1, 1], [2, 2, 3, 3, 4, 4], [5, 6], [7, 7, 8, 8, 9]]\n",
    "TEST_ROUTES = [8, 9]\n",
    "INTERVAL = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"MAC counting\"\"\"\n",
    "def get_mac_structure(routes, test_route):\n",
    "    # Only for the train data\n",
    "    # create list of mac addresses for all the samples\n",
    "    total_macs = []\n",
    "    for i in range(len(wifi)):\n",
    "        for j in range(len(wifi[i])):\n",
    "            if routes[i][j] != test_route:\n",
    "                track_mac_array = wifi[i][j]['MAC'].values\n",
    "                for mac_add in track_mac_array:\n",
    "                    if not mac_add in total_macs:\n",
    "                        total_macs.append(mac_add)\n",
    "                        \n",
    "    # create list of mac addresses for each building\n",
    "    building_macs = {10: [], 20: [], 30: [], 40: []}\n",
    "    for i in range(len(wifi)):\n",
    "        for j in range(len(wifi[i])):\n",
    "            if routes[i][j] != test_route:\n",
    "                track_mac_array = wifi[i][j]\n",
    "                for k in range(track_mac_array.shape[0]):\n",
    "                    mac_line = track_mac_array.iloc[k]\n",
    "                    mac = mac_line['MAC']\n",
    "                    build = int(mac_line['POSI_building'])\n",
    "                    if not mac in building_macs[build]:\n",
    "                        building_macs[build].append(mac)\n",
    "\n",
    "    # create list of mac addresses for each building for each floor\n",
    "    floor_macs = {10: [[], [], [], [], [], []], 20: [[], [], [], [], [], []], \n",
    "                  30: [[], [], [], [], [], []], 40: [[], [], [], [], [], []]}\n",
    "    for i in range(len(wifi)):\n",
    "        for j in range(len(wifi[i])):\n",
    "            if routes[i][j] != test_route:\n",
    "                track_mac_array = wifi[i][j]\n",
    "                for k in range(track_mac_array.shape[0]):\n",
    "                    mac_line = track_mac_array.iloc[k]\n",
    "                    mac = mac_line['MAC']\n",
    "                    build = int(mac_line['POSI_building'])\n",
    "                    floor = int(mac_line['POSI_floor'])\n",
    "                    if not mac in floor_macs[build][floor]:\n",
    "                        floor_macs[build][floor].append(mac)\n",
    "                        \n",
    "#     # print mac statistics\n",
    "#     if DEBUG:\n",
    "#         print('total macs')\n",
    "#         print(len(total_macs))\n",
    "#         print('building macs')\n",
    "#         for build in sorted(building_macs):\n",
    "#             print(build, len(building_macs[build]), ',')\n",
    "#         print('floor macs')\n",
    "#         for build in sorted(floor_macs):\n",
    "#             for j in range(len(floor_macs[build])):\n",
    "#                 print(build, j, len(floor_macs[build][j]), ',')\n",
    "    return [total_macs, building_macs, floor_macs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"WiFi functions\"\"\"\n",
    "# Make WiFi data into global dummy variable\n",
    "def dummify_wifi(wifi_df, wifi_list):\n",
    "    wifi_samples = np.unique(wifi_df['AppTime'].values)\n",
    "    wifi_dummy = np.ones((wifi_samples.shape[0], len(wifi_list))) * -200\n",
    "    wifi_dummy = pd.DataFrame(wifi_dummy, columns=wifi_list, index=wifi_samples)\n",
    "    for i, sample_time in enumerate(wifi_samples):\n",
    "            wifi_cur = wifi_df.iloc[wifi_df['AppTime'].values == sample_time]\n",
    "            for j in range(wifi_cur.shape[0]):\n",
    "                if str(wifi_cur['MAC'].iat[j]) in wifi_list:\n",
    "                    wifi_dummy[wifi_cur['MAC'].iat[j]].iat[i] = wifi_cur['rssi'].iat[j]\n",
    "    wifi_dummy = normalize_wifi(wifi_dummy)\n",
    "    wifi_dummy = add_results_wifi(wifi_dummy, wifi_df)\n",
    "    return wifi_dummy\n",
    "\n",
    "# Normalize wifi and cut noise\n",
    "def normalize_wifi(wifi_dummy_df):\n",
    "    max_per_line = np.amax(wifi_dummy_df, axis=1)\n",
    "    wifi_dummy_df.iloc[:, :] = wifi_dummy_df.values - max_per_line.reshape((max_per_line.shape[0], 1))\n",
    "    return wifi_dummy_df\n",
    "\n",
    "# Add ground truth columnns to the wifi dataframe\n",
    "def add_results_wifi(df, results_df):\n",
    "    df['POSI_building'] = np.ones((df.shape[0],))\n",
    "    df['POSI_floor'] = np.ones((df.shape[0],))\n",
    "    df['interp_lat'] = np.ones((df.shape[0],))\n",
    "    df['interp_lon'] = np.ones((df.shape[0],))\n",
    "    wifi_samples = df.index.values\n",
    "    for i, sample_time in enumerate(wifi_samples):\n",
    "        results_cur = results_df.iloc[results_df['AppTime'].values == sample_time]\n",
    "        for j in range(results_cur.shape[0]):\n",
    "            df['POSI_building'].iat[i] = results_cur['POSI_building'].iat[0]\n",
    "            df['POSI_floor'].iat[i] = results_cur['POSI_floor'].iat[0]\n",
    "            df['interp_lat'].iat[i] = results_cur['interp_lat'].iat[0]\n",
    "            df['interp_lon'].iat[i] = results_cur['interp_lon'].iat[0]\n",
    "    return df\n",
    "\n",
    "# Make WiFi data into dummy variable with the buildingIDs as values. \n",
    "# In each row the number of MACs associated with the buildingID is the value\n",
    "def dummify_wifi_building(wifi_df, wifi_building_list):\n",
    "    wifi_samples = np.unique(wifi_df['AppTime'].values)\n",
    "    wifi_dummy = np.zeros((wifi_samples.shape[0], len(wifi_building_list)))\n",
    "    wifi_dummy = pd.DataFrame(wifi_dummy, columns=list(wifi_building_list.keys()), index=wifi_samples)\n",
    "    for i, sample_time in enumerate(wifi_samples):\n",
    "            wifi_cur = wifi_df.iloc[wifi_df['AppTime'].values == sample_time]\n",
    "            for j in range(wifi_cur.shape[0]):\n",
    "                for k in wifi_building_list:\n",
    "                    if str(wifi_cur['MAC'].iat[j]) in wifi_building_list[k]:\n",
    "                        wifi_dummy[k].iat[i] += 1\n",
    "    wifi_dummy = add_results_wifi(wifi_dummy, wifi_df)\n",
    "    return wifi_dummy\n",
    "\n",
    "# level noise when packets have lower power than it\n",
    "def wifi_level_noise(wifi_dummy_df, noise):\n",
    "    if len(wifi_dummy_df.shape) > 1:\n",
    "        noise_not = (wifi_dummy_df.values >= noise) * 1\n",
    "        wifi_dummy_df.iloc[:, :] = noise_not * wifi_dummy_df.values + (1- noise_not) * noise\n",
    "    else:\n",
    "        noise_not = (wifi_dummy_df.values >= noise) * 1\n",
    "        wifi_dummy_df.iloc[:] = noise_not * wifi_dummy_df.values + (1- noise_not) * noise\n",
    "    return wifi_dummy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Grid class\"\"\"\n",
    "# Change measurement from meters to differnial earth angle\n",
    "def mtod_calc(local_latitude, mes_m):\n",
    "    local_radius = 6378137 * np.cos(np.pi * local_latitude / 180)\n",
    "    mes_d = 360 * mes_m / (local_radius * 2 * np.pi)\n",
    "    return mes_d\n",
    "\n",
    "# Calculate errors\n",
    "def dtom_calc(local_latitude, mes_d):\n",
    "    local_radius = 6378137 * np.cos(np.pi * local_latitude / 180)\n",
    "    mes_m = mes_d * (local_radius * 2 * np.pi) / 360\n",
    "    return mes_m\n",
    "\n",
    "# Create the grid for fingerprinting\n",
    "class GridTrain:\n",
    "    def __init__(self, lat_samples, lon_samples, resolution_m, rssis, translate, classifier):\n",
    "        self.lat_lim = (np.min(lat_samples), np.max(lat_samples))\n",
    "        self.lon_lim = (np.min(lon_samples), np.max(lon_samples))\n",
    "        self.lat_loc = np.median(lat_samples)\n",
    "        self.resolution = mtod_calc(self.lat_loc, resolution_m)\n",
    "        self.lat_grid_start = self.lat_lim[0] + mtod_calc(self.lat_loc, translate[0])\n",
    "        self.lon_grid_start = self.lon_lim[0] + mtod_calc(self.lat_loc, translate[1])\n",
    "        self.grid_lat = np.arange(self.lat_grid_start, self.lat_lim[1], self.resolution)\n",
    "        self.grid_lon = np.arange(self.lon_grid_start, self.lon_lim[1], self.resolution)\n",
    "        self.grid_rssis, self.grid_cell_id, self.grid_dict = self.fit_rssis_to_grid(lat_samples, lon_samples, rssis)\n",
    "        self.classifier = classifier\n",
    "        self.classifier.fit(self.grid_rssis.values, self.grid_cell_id)\n",
    "        \n",
    "    # Allocate packets to a cell\n",
    "    def fit_rssis_to_grid(self, lat_samples, lon_samples, rssis):\n",
    "        rssis_noise_lim = wifi_level_noise(rssis, -25)\n",
    "        grid_rssis = []\n",
    "        grid_cell_id = []\n",
    "        grid_dict = {}\n",
    "        cur_cell_id = 0\n",
    "        for i in range(self.grid_lat.shape[0]):\n",
    "            for j in range(self.grid_lon.shape[0]):\n",
    "                inside_lat = np.logical_and(lat_samples >= self.grid_lat[i], \n",
    "                                            lat_samples < (self.grid_lat[i] + self.resolution))\n",
    "                inside_lon = np.logical_and(lon_samples >= self.grid_lon[j], \n",
    "                                            lon_samples < (self.grid_lon[j] + self.resolution))\n",
    "                inside_cell = np.logical_and(inside_lat, inside_lon)\n",
    "                if np.sum(inside_cell):\n",
    "                    grid_rssis.append(rssis.iloc[inside_cell])\n",
    "                    grid_cell_id.append(np.repeat(cur_cell_id, np.sum(inside_cell)))\n",
    "                    grid_dict[cur_cell_id] = [self.grid_lat[i] + 0.5 * self.resolution, \n",
    "                                              self.grid_lon[j] + 0.5 * self.resolution]\n",
    "                    cur_cell_id += 1\n",
    "        grid_cell_id = np.hstack(tuple(grid_cell_id))\n",
    "        grid_rssis = pd.concat(grid_rssis, axis=0)\n",
    "        return(grid_rssis, grid_cell_id, grid_dict)\n",
    "    \n",
    "    # Predict from classifier\n",
    "    def predict_classifier(self, testset):\n",
    "        self.classifier.predict(testset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# print an image of the predicitions\n",
    "def show_prediction(results, predictions, route):\n",
    "    # Plot 2D predicitions\n",
    "    plt.figure(1, figsize=(15, 15))\n",
    "    plt.subplot(421)\n",
    "    plt.plot(results[route].index.values, results[route]['Lat'].values, 'r',\n",
    "             predictions[route].index.values, predictions[route]['Lat'].values, 'bo')\n",
    "    plt.title('Lat(t): Route - red; WiFi fingerprinting - blue')\n",
    "    plt.subplot(422)\n",
    "    plt.plot(results[route].index.values, results[route]['Lon'].values, 'r',\n",
    "             predictions[route].index.values, predictions[route]['Lon'].values, 'bo')\n",
    "    plt.title('Lng(t): Route - red; WiFi fingerprinting - blue')\n",
    "    plt.subplot(423)\n",
    "    plt.plot(results[route].index.values, results[route]['FloorID'].values, 'r',\n",
    "             predictions[route].index.values, predictions[route]['FloorID'].values, 'bo')\n",
    "    plt.title('FloorID: Route - red; WiFi fingerprinting - blue')\n",
    "    plt.subplot(424)\n",
    "    plt.plot(results[route].index.values, results[route]['BuildingID'].values, 'r',\n",
    "             predictions[route].index.values, predictions[route]['BuildingID'].values, 'bo')\n",
    "    plt.title('FloorID: Route - red; WiFi fingerprinting - blue')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Smooth signal \n",
    "\"\"\"need to add trend\"\"\"\n",
    "def exp_smooth(time_series, sensor_series, alpha, trend):\n",
    "    # forward in time\n",
    "    sensor_forward = np.zeros((sensor_series.shape))\n",
    "    sensor_forward[0] = sensor_series[0]\n",
    "    for i in range(1, time_series.shape[0]):\n",
    "        dt = time_series[i] - time_series[i-1]\n",
    "        sensor_forward[i] = alpha * sensor_series[i] + (1 - alpha) * sensor_forward[i-1]\n",
    "    # backwards in time\n",
    "    sensor_backwards = np.zeros((sensor_series.shape))\n",
    "    sensor_trend = np.zeros((sensor_series.shape))\n",
    "    sensor_backwards[-1] = sensor_series[-1]\n",
    "    for i in range(time_series.shape[0]-2, -1, -1):\n",
    "        dt = time_series[i+1] - time_series[i]\n",
    "        sensor_backwards[i] = alpha * sensor_series[i] + (1 - alpha) * sensor_backwards[i+1]\n",
    "    sensor_smoothed = (sensor_forward + sensor_backwards) / 2\n",
    "    return sensor_smoothed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Interpolate wifi to tested time stamps\n",
    "def int_wifi_to_sub(time_samples, pred):\n",
    "    test_sub_pred = pd.DataFrame(np.zeros((time_samples.shape[0], 4)), index=time_samples, \n",
    "                                 columns=['Lat', 'Lon', 'FloorID', 'BuildingID'])\n",
    "    # Pad sensors' samples\n",
    "    latlon_pad_start = pred[['Lat', 'Lon']].iloc[0]\n",
    "    latlon_pad_end = pred[['Lat', 'Lon']].iloc[-1]\n",
    "    latlon_array = np.vstack((latlon_pad_start, \n",
    "                              pred[['Lat', 'Lon']].values, \n",
    "                              latlon_pad_end))\n",
    "    floor_pad_start = pred['FloorID'].iloc[0]\n",
    "    floor_pad_end = pred['FloorID'].iloc[-1]\n",
    "    floor_array = np.hstack((floor_pad_start, \n",
    "                             pred['FloorID'].values, \n",
    "                             floor_pad_end))\n",
    "    building_pad_start = pred['BuildingID'].iloc[0]\n",
    "    building_pad_end = pred['BuildingID'].iloc[-1]\n",
    "    building_array = np.hstack((building_pad_start, \n",
    "                               pred['BuildingID'].values, \n",
    "                               building_pad_end))\n",
    "    time_pad_start = 0\n",
    "    time_pad_end = time_samples[-1]\n",
    "    time_array = np.hstack((time_pad_start, \n",
    "                            pred.index.values, \n",
    "                            time_pad_end))\n",
    "    \n",
    "    # Interpolate sensors' samples\n",
    "    interp_pred_wifi_lat = interpolate.interp1d(time_array, latlon_array[:, 0])\n",
    "    interp_pred_wifi_lon = interpolate.interp1d(time_array, latlon_array[:, 1])\n",
    "    interp_pred_wifi_floor = interpolate.interp1d(time_array, floor_array)\n",
    "    interp_pred_wifi_building = interpolate.interp1d(time_array, building_array)\n",
    "    test_sub_pred['Lat'] = interp_pred_wifi_lat(test_sub_pred.index.values)\n",
    "    test_sub_pred['Lon'] = interp_pred_wifi_lon(test_sub_pred.index.values)\n",
    "    test_sub_pred['FloorID'] = interp_pred_wifi_floor(test_sub_pred.index.values)\n",
    "    test_sub_pred['BuildingID'] = interp_pred_wifi_building(test_sub_pred.index.values)\n",
    "    test_sub_pred['FloorID'] = (test_sub_pred['FloorID'].values + 0.5).astype(int)\n",
    "    \n",
    "    return test_sub_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.grid_search import ParameterGrid\n",
    "\n",
    "param_grid = {\n",
    "          'building_alpha': [0.05],\n",
    "          'building_trend': [0.05],\n",
    "          'floor_alpha': [0.2],\n",
    "          'floor_trend': [0],\n",
    "          'floor_noise': [{10: -10, 20: -10, 30: -10, 40: -10}], \n",
    "          'floor_n': [200],\n",
    "          'floor_depth': [{10: 1, 20: 5, 30: 5, 40: 5}],\n",
    "          'floor_features': [{10: 1, 20: 1.0, 30: 1.0, 40: 1.0}],\n",
    "          'grid_noise': [{10: -25, 20: -25, 30: -25, 40: -25}],\n",
    "          'gps_aid': [False],\n",
    "          'cell_size': [10],\n",
    "          'grid_alpha': [1],\n",
    "          'grid_trend': [0]\n",
    "         }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterations for optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'building_alpha': 0.05, 'grid_alpha': 1, 'floor_features': {40: 1.0, 10: 1, 20: 1.0, 30: 1.0}, 'grid_trend': 0, 'floor_trend': 0, 'floor_n': 200, 'floor_alpha': 0.2, 'floor_noise': {40: -10, 10: -10, 20: -10, 30: -10}, 'cell_size': 10, 'building_trend': 0.05, 'grid_noise': {40: -25, 10: -25, 20: -25, 30: -25}, 'gps_aid': False, 'floor_depth': {40: 5, 10: 1, 20: 5, 30: 5}}\n",
      "For test route 8\n",
      "Creating dummy WiFi dataframes\n",
      "Creating training datasets\n",
      "Training RF"
     ]
    }
   ],
   "source": [
    "for params in ParameterGrid(param_grid):\n",
    "    print(params)\n",
    "    for cur_test_route in TEST_ROUTES:\n",
    "        print('For test route %d' % cur_test_route)\n",
    "        # Create macs database\n",
    "        total_macs, building_macs, floor_macs = get_mac_structure(ROUTES, cur_test_route)\n",
    "\n",
    "        # Restarting variables\n",
    "        wifi_dummy_building = []\n",
    "        wifi_dummy_total = []\n",
    "\n",
    "        train_build = []\n",
    "        train_wifi = []\n",
    "        train_floor = {10: 0, 20: 0, 30: 0, 40: 0}\n",
    "        train_floor_results = {10: 0, 20: 0, 30: 0, 40: 0}\n",
    "        train_2d = {10: [[], [], [], [], [], []], 20: [[], [], [], [], [], []], \n",
    "                    30: [[], [], [], [], [], []], 40: [[], [], [], [], [], []]}\n",
    "        train_2d_lat = {10: [[], [], [], [], [], []], 20: [[], [], [], [], [], []], \n",
    "                        30: [[], [], [], [], [], []], 40: [[], [], [], [], [], []]}\n",
    "        train_2d_lon = {10: [[], [], [], [], [], []], 20: [[], [], [], [], [], []], \n",
    "                        30: [[], [], [], [], [], []], 40: [[], [], [], [], [], []]}\n",
    "        train_2d_grid_results = {10: [[], [], [], [], [], []], 20: [[], [], [], [], [], []], \n",
    "                                 30: [[], [], [], [], [], []], 40: [[], [], [], [], [], []]}\n",
    "        \n",
    "        rfc_floor = {10: 0, 20: 0, 30: 0, 40: 0}\n",
    "\n",
    "        train_2d_grid = {10: [[], [], [], [], [], []], 20: [[], [], [], [], [], []], \n",
    "                        30: [[], [], [], [], [], []], 40: [[], [], [], [], [], []]}\n",
    "        train_2d_grid_results = {10: [[], [], [], [], [], []], 20: [[], [], [], [], [], []], \n",
    "                                 30: [[], [], [], [], [], []], 40: [[], [], [], [], [], []]}\n",
    "        \n",
    "        test_wifi = []\n",
    "        test_build = []\n",
    "        test_wifi_results = []\n",
    "\n",
    "        predicted_build = []\n",
    "        predicted_build_proba = []\n",
    "        predicted_build_proba_smoothed = []\n",
    "        predicted_build_smoothed = []\n",
    "        \n",
    "        predicted_floor = []\n",
    "        predicted_floor_proba = []\n",
    "        predicted_floor_smoothed = []\n",
    "        predicted_floor_proba_smoothed = []\n",
    "        \n",
    "        predicted_cell = []\n",
    "        predicted_2d = []\n",
    "        \n",
    "        test_predictions = []\n",
    "        \n",
    "        test_sub_timestamps = []        \n",
    "        test_sub_results = [] \n",
    "        test_sub_predicitions = [] \n",
    "\n",
    "        gps = []\n",
    "        test_gps = []\n",
    "\n",
    "        eval_errors = []\n",
    "        \n",
    "        \"\"\"Converting WiFi into dummy variables\"\"\"\n",
    "        print('Creating dummy WiFi dataframes')\n",
    "        # Create building wifi dummy variable\n",
    "        for i in range(len(wifi)):\n",
    "            wifi_dummy_building.append([])\n",
    "            for j in range(len(wifi[i])):\n",
    "                wifi_dummy_building[i].append(dummify_wifi_building(wifi[i][j], building_macs))\n",
    "\n",
    "        # Create wifi dummy variable\n",
    "        for i in range(len(wifi)):\n",
    "            wifi_dummy_total.append([])\n",
    "            for j in range(len(wifi[i])):\n",
    "                wifi_dummy_total[i].append(dummify_wifi(wifi[i][j], total_macs))\n",
    "\n",
    "        \"\"\"Train data\"\"\"\n",
    "        print('Creating training datasets')\n",
    "        # Create building train\n",
    "        for i in range(len(wifi_dummy_total)):\n",
    "            for j in range(len(wifi_dummy_total[i])):\n",
    "                if ROUTES[i][j] != cur_test_route:\n",
    "                    train_build.append(wifi_dummy_building[i][j])\n",
    "        train_build = pd.concat(train_build, axis=0)\n",
    "        train_build_results = train_build['POSI_building']\n",
    "        train_build = train_build[[10, 20, 30, 40]]\n",
    "\n",
    "        # Create wifi train file\n",
    "        for i in range(len(wifi_dummy_total)):\n",
    "            for j in range(len(wifi_dummy_total[i])):\n",
    "                if ROUTES[i][j] != cur_test_route:\n",
    "                    train_wifi.append(wifi_dummy_total[i][j])\n",
    "        train_wifi = pd.concat(train_wifi, axis=0)    \n",
    "\n",
    "        # Create floor train\n",
    "        for building in train_floor:\n",
    "            train_floor[building] = train_wifi.iloc[train_build_results.values == building][building_macs[building]]\n",
    "            train_floor[building] = wifi_level_noise(train_floor[building], -10)\n",
    "            train_floor_results[building] = train_wifi.iloc[train_build_results.values == building]['POSI_floor']\n",
    "        \n",
    "        # Create 2D train\n",
    "        for i in range(len(wifi_dummy_total)):\n",
    "            for j in range(len(wifi_dummy_total[i])):\n",
    "                if ROUTES[i][j] != cur_test_route:\n",
    "                    track_mac_array = wifi_dummy_total[i][j]\n",
    "                    for k in range(track_mac_array.shape[0]):\n",
    "                        mac_line = track_mac_array.iloc[k]\n",
    "                        build = int(mac_line['POSI_building'])\n",
    "                        floor = int(mac_line['POSI_floor'])\n",
    "                        lat = float(mac_line['interp_lat'])\n",
    "                        lon = float(mac_line['interp_lon'])\n",
    "                        train_2d[build][floor].append(mac_line[floor_macs[build][floor]].values.reshape((1, len(floor_macs[build][floor]))))\n",
    "                        train_2d_lat[build][floor].append(lat)\n",
    "                        train_2d_lon[build][floor].append(lon)\n",
    "\n",
    "        # Concat samples inside each floor\n",
    "        for build in train_2d:\n",
    "            for floor in range(len(train_2d[build])):\n",
    "                if len(train_2d[build][floor]):\n",
    "                    train_2d[build][floor] = np.vstack(tuple(train_2d[build][floor]))\n",
    "                    train_2d[build][floor] = pd.DataFrame(train_2d[build][floor], columns=floor_macs[build][floor])\n",
    "        \n",
    "        \"\"\"Train ML\"\"\"\n",
    "        print('Training RF')\n",
    "        # Train building\n",
    "        rfc_build = RandomForestClassifier(n_estimators=100, max_depth=4 ,max_features=1, random_state=2016)\n",
    "        rfc_build.fit(train_build.values, train_build_results.values)\n",
    "\n",
    "        # Train floor\n",
    "        for building in rfc_floor:\n",
    "            rfc_floor[building] = RandomForestClassifier(n_estimators=params['floor_n'], \n",
    "                                                         max_depth=params['floor_depth'][building], \n",
    "                                                         max_features=params['floor_features'][building], \n",
    "                                                         random_state=2016)\n",
    "            rfc_floor[building].fit(train_floor[building].values, train_floor_results[building].values)\n",
    "            \n",
    "        # Train grid\n",
    "        for build in train_2d:\n",
    "            for floor in range(len(train_2d[build])):\n",
    "                if len(train_2d[build][floor]):\n",
    "                    train_2d_grid[build][floor] = GridTrain(train_2d_lat[build][floor], \n",
    "                                                            train_2d_lon[build][floor], params['cell_size'], \n",
    "                                                            train_2d[build][floor], (-0.5 * params['cell_size'], \n",
    "                                                                                     -0.5 * params['cell_size']),\n",
    "                                                            RandomForestClassifier(n_estimators=200, max_depth=20,\n",
    "                                                                                   max_features=0.5, random_state=2016))\n",
    "        \"\"\"Test data\"\"\"\n",
    "        print('Creating test datasets')\n",
    "        if EVAL:\n",
    "            # Create test answers dataframe\n",
    "            for i in range(len(wifi_dummy_building)):\n",
    "                for j in range(len(wifi_dummy_building[i])):\n",
    "                    if ROUTES[i][j] == cur_test_route:\n",
    "                        test_wifi_results.append(pd.DataFrame(np.zeros((wifi_dummy_building[i][j].shape[0], 4)), \n",
    "                                                              index=wifi_dummy_building[i][j].index.values, \n",
    "                                                              columns=['Lat', 'Lon', 'FloorID', 'BuildingID']))\n",
    "                        test_wifi_results[-1]['Lat'] = wifi_dummy_total[i][j]['interp_lat'].values.astype(float)\n",
    "                        test_wifi_results[-1]['Lon'] = wifi_dummy_total[i][j]['interp_lon'].values.astype(float)\n",
    "                        test_wifi_results[-1]['FloorID'] = wifi_dummy_total[i][j]['POSI_floor'].values\n",
    "                        test_wifi_results[-1]['BuildingID'] = wifi_dummy_total[i][j]['POSI_building'].values\n",
    "\n",
    "        # Create building test\n",
    "        for i in range(len(wifi_dummy_building)):\n",
    "            for j in range(len(wifi_dummy_building[i])):\n",
    "                if ROUTES[i][j] == cur_test_route:\n",
    "                    test_build.append(wifi_dummy_building[i][j][[10, 20, 30, 40]])\n",
    "\n",
    "        # Create wifi test file\n",
    "        for i in range(len(wifi_dummy_total)):\n",
    "            for j in range(len(wifi_dummy_total[i])):\n",
    "                if ROUTES[i][j] == cur_test_route:\n",
    "                    test_wifi.append(wifi_dummy_total[i][j])\n",
    "\n",
    "        \"\"\"Predict test data, need to add smoothing\"\"\"\n",
    "        print('Prediciting test results')\n",
    "\n",
    "        # Create test predictions dataframe\n",
    "        for i in range(len(wifi_dummy_building)):\n",
    "            for j in range(len(wifi_dummy_building[i])):\n",
    "                if ROUTES[i][j] == cur_test_route:\n",
    "                    test_predictions.append(pd.DataFrame(np.zeros((wifi_dummy_building[i][j].shape[0], 4)), \n",
    "                                                         index=wifi_dummy_building[i][j].index.values, \n",
    "                                                         columns=['Lat', 'Lon', 'FloorID', 'BuildingID']))\n",
    "\n",
    "        # Predict buildingID\n",
    "        for i in range(len(test_build)):\n",
    "            predicted_build.append(rfc_build.predict(test_build[i].values))\n",
    "            predicted_build_proba.append(rfc_build.predict_proba(test_build[i].values))\n",
    "            # Smooth probabilities\n",
    "            predicted_build_proba_smoothed.append(np.zeros(predicted_build_proba[i].shape))\n",
    "            predicted_build_smoothed.append(np.zeros(predicted_build_proba[i].shape[0], ))\n",
    "            for j in range(predicted_build_proba[i].shape[1]):\n",
    "                predicted_build_proba_smoothed[i][:, j] = exp_smooth(test_build[i].index.values, \n",
    "                                                                     predicted_build_proba[i][:, j], \n",
    "                                                                     params['building_alpha'], \n",
    "                                                                     params['building_trend'])\n",
    "            # Smoothed result\n",
    "            predicted_max = np.argmax(predicted_build_proba_smoothed[i], axis=1)\n",
    "            for j in range(predicted_max.shape[0]):\n",
    "                predicted_build_smoothed[i][j] = rfc_build.classes_[predicted_max[i]] \n",
    "            test_predictions[i]['BuildingID'] = predicted_build_smoothed[i]\n",
    "            if EVAL and DEBUG:\n",
    "                print('\\n', 'Test BuildingID probabality #%d' %i, \n",
    "                      np.sum(test_predictions[i]['BuildingID'].values == test_wifi_results[i]['BuildingID'].values) / \n",
    "                      test_wifi_results[i].shape[0])\n",
    "            \n",
    "        # Predict floorID\n",
    "        for test_i in range(len(test_wifi)):\n",
    "            predicted_floor.append([])\n",
    "            predicted_floor_proba.append([])\n",
    "            for row_i in range(test_wifi[test_i].shape[0]):\n",
    "                cur_pred_build = predicted_build[test_i][row_i]\n",
    "                cur_measurement = test_wifi[test_i][building_macs[cur_pred_build]].iloc[row_i]\n",
    "                cur_measurement = wifi_level_noise(cur_measurement, \n",
    "                                                   params['floor_noise'][test_predictions[test_i]['BuildingID'].iloc[row_i]])\n",
    "                predicted_floor[test_i].append(int(rfc_floor[cur_pred_build].predict([cur_measurement.values])))\n",
    "                predicted_floor_proba[test_i].append(rfc_floor[cur_pred_build].predict_proba([cur_measurement.values])[0])\n",
    "            predicted_floor_proba[test_i] = np.array(predicted_floor_proba[test_i])\n",
    "            print(predicted_floor_proba[test_i].shape)\n",
    "            # Smooth probabilities                                            \n",
    "            predicted_floor_proba_smoothed.append(np.zeros(predicted_floor_proba[test_i].shape))\n",
    "            predicted_floor_smoothed.append(np.zeros(predicted_floor_proba[test_i].shape[0], ))\n",
    "            for j in range(predicted_floor_proba[test_i].shape[1]):\n",
    "                predicted_floor_proba_smoothed[test_i][:, j] = exp_smooth(test_wifi[test_i].index.values, \n",
    "                                                                          predicted_floor_proba[test_i][:, j],\n",
    "                                                                          params['floor_alpha'], params['floor_trend'])\n",
    "            # Smoothed result\n",
    "            predicted_max = np.argmax(predicted_floor_proba_smoothed[test_i], axis=1)\n",
    "            for j in range(predicted_max.shape[0]):\n",
    "                predicted_floor_smoothed[test_i][j] = rfc_floor[cur_pred_build].classes_[predicted_max[j]]\n",
    "            test_predictions[test_i]['FloorID'] = predicted_floor_smoothed[test_i]\n",
    " \n",
    "        # Predict 2Dgrid\n",
    "        for test_i in range(len(test_wifi)):\n",
    "            predicted_cell.append([])\n",
    "            predicted_2d.append([])\n",
    "            for row_i in range(test_wifi[test_i].shape[0]):\n",
    "                cur_pred_build = predicted_build[test_i][row_i]\n",
    "                cur_pred_floor = predicted_floor[test_i][row_i]\n",
    "                cur_measurement = test_wifi[test_i][floor_macs[cur_pred_build][cur_pred_floor]].iloc[row_i]\n",
    "                cur_measurement = wifi_level_noise(cur_measurement, params['grid_noise'][cur_pred_build])\n",
    "                cur_prediction = int(train_2d_grid[cur_pred_build][cur_pred_floor].classifier.predict([cur_measurement.values]))\n",
    "                predicted_cell[test_i].append(cur_prediction)\n",
    "                predicted_2d[test_i].append(train_2d_grid[cur_pred_build][cur_pred_floor].grid_dict[cur_prediction])\n",
    "            predicted_2d[test_i] = np.array(predicted_2d[test_i])\n",
    "            test_predictions[test_i]['Lat'] = exp_smooth(test_wifi[test_i].index.values, \n",
    "                                                         predicted_2d[test_i][:, 0],\n",
    "                                                         params['grid_alpha'], params['grid_trend'])\n",
    "            test_predictions[test_i]['Lon'] = exp_smooth(test_wifi[test_i].index.values, \n",
    "                                                         predicted_2d[test_i][:, 1],\n",
    "                                                         params['grid_alpha'], params['grid_trend'])\n",
    "        \n",
    "        \"\"\"GPS prediction\"\"\"\n",
    "        if params['gps_aid']:\n",
    "            for i in range(len(track)):\n",
    "                gps.append([])\n",
    "                for j in range(len(track[i])):\n",
    "                    gps[-1].append(track[i][j][[1, 3, 4, 5, 6, 7, 8, 9, 10, 'POSI_floor', 'POSI_building', 'interp_lat',\n",
    "                                                'interp_lon']].iloc[track[i][j][0].values == 'GNSS'])\n",
    "                    gps[-1][-1].columns = ['AppTime', 'GPS_lat', 'GPS_lon', 'GPS_alt', 'GPS_bearing', 'GPS_accuracy', \n",
    "                                           'GPS_speed', 'GPS_sat_viewed', 'GPS_sat_used', 'POSI_floor', 'POSI_building', \n",
    "                                           'interp_lat', 'interp_lon']\n",
    "                    gps[-1][-1].index = gps[-1][-1]['AppTime'].values\n",
    "                    gps[-1][-1] = gps[-1][-1].drop(['AppTime'], axis=1)\n",
    "                    if ROUTES[i][j] == cur_test_route:\n",
    "                        test_gps.append(gps[i][j])\n",
    "        \n",
    "        \"\"\"Interpolate to wanted time stamps\"\"\"\n",
    "        # Create a test answer with 0.5 seconds intervals\n",
    "        test_i = 0\n",
    "        for i in range(len(track)):\n",
    "            for j in range(len(track[i])):\n",
    "                if ROUTES[i][j] == cur_test_route:\n",
    "                    last_sample_time = track[i][j][1].iloc[-1]\n",
    "                    test_sub_timestamps.append(np.arange(0, last_sample_time, INTERVAL))\n",
    "                    test_sub_predicitions.append(int_wifi_to_sub(test_sub_timestamps[-1], test_predictions[test_i]))\n",
    "                    if EVAL:\n",
    "                        test_sub_results.append(int_wifi_to_sub(test_sub_timestamps[-1], test_wifi_results[test_i]))\n",
    "                    test_i += 1\n",
    "                    \n",
    "        \"\"\"Plot predicitons\"\"\"\n",
    "        if EVAL and DEBUG:\n",
    "            for i in range(len(test_build)):\n",
    "                show_prediction(test_sub_results, test_sub_predicitions, i)\n",
    "\n",
    "        \"\"\"Evaluate errors\"\"\"\n",
    "#         if EVAL:\n",
    "        \"\"\"Write to file\"\"\"\n",
    "\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
